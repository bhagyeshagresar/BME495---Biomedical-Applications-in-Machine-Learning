{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Midterm Project 3 (100 points total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this project, you need to use neural networks: Build a Feed-forward Neural Network and a Convolutional Neural Network using Keras library to classify patients with heart conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary libraries. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, classification_report\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, InputLayer, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After that, upload the data and preprocess it. (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    72471\n",
      "4.0     6431\n",
      "2.0     5788\n",
      "1.0     2223\n",
      "3.0      641\n",
      "Name: 187, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Upload the data and save it to a Dataframe.\n",
    "data = pd.read_csv('Heartbeat_dataset.csv', header=None)\n",
    "data = pd.DataFrame(data)\n",
    "data1 = data.iloc[:, :-1]\n",
    " \n",
    "#Plot the heartbeat of one patient.\n",
    "row1 = data1.iloc[0]\n",
    "row1.plot()\n",
    "\n",
    "# Check the class distribution. (Hint: Use .value_counts attribute and \n",
    "# remember that the labels are at the last column of the dataframe)\n",
    "data_cd = data.iloc[:, -1]\n",
    "print(data_cd.value_counts())\n",
    "\n",
    "# You should see that class 0 has more than 5 times as many instances as all other classes combined.\n",
    "# Make the dataset more balanced by sampling the instances with class 0.\n",
    "# Filter all the data that don't have class 0 to a new dataframe.\n",
    "data_zeros = data[data.iloc[:, -1] == 0]\n",
    "data_zeros_col = data_zeros.iloc[:, -1]\n",
    "\n",
    "\n",
    "data_non_zeros = data[data.iloc[:, -1] != 0]\n",
    "data_non_zeros_col = data_non_zeros.iloc[:, -1]\n",
    "\n",
    "\n",
    "# From all the data that has class 0 (again use filtering), sample 8000 instances and save it to a new dataframe. \n",
    "#(Hint: Use .sample attribute)\n",
    "data_zeros_new = data_zeros.sample(n=8000, random_state = 1)\n",
    "\n",
    "\n",
    "# Concatenate the two new dataframes.\n",
    "data_concat_list = [data_zeros_new, data_non_zeros]\n",
    "data_new_concat = pd.concat(data_concat_list)\n",
    "\n",
    "\n",
    "# Check the new class distribution.\n",
    "\n",
    "# Finally, separate the features and the labels into X and y variables.\n",
    "X = data_new_concat.iloc[:, :-1]\n",
    "y = data_new_concat.iloc[:, -1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training and test sets. Use a 90-10 split ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the training and test sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.1)\n",
    "\n",
    "\n",
    "#Convert the sets into NumPy arrays (Necessary for Keras models)\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a feed-forward neural network with 5 layers. (One input, three hidden, one output) (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.5297 - accuracy: 0.8136 - val_loss: 0.4264 - val_accuracy: 0.8436\n",
      "Epoch 2/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.3264 - accuracy: 0.8863 - val_loss: 0.3297 - val_accuracy: 0.8807\n",
      "Epoch 3/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.2712 - accuracy: 0.9085 - val_loss: 0.2711 - val_accuracy: 0.9033\n",
      "Epoch 4/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.2368 - accuracy: 0.9190 - val_loss: 0.2463 - val_accuracy: 0.9225\n",
      "Epoch 5/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.2170 - accuracy: 0.9230 - val_loss: 0.2711 - val_accuracy: 0.9167\n",
      "Epoch 6/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.2003 - accuracy: 0.9322 - val_loss: 0.2305 - val_accuracy: 0.9201\n",
      "Epoch 7/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.1830 - accuracy: 0.9351 - val_loss: 0.2223 - val_accuracy: 0.9235\n",
      "Epoch 8/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.1709 - accuracy: 0.9416 - val_loss: 0.2007 - val_accuracy: 0.9321\n",
      "Epoch 9/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.1583 - accuracy: 0.9451 - val_loss: 0.2022 - val_accuracy: 0.9321\n",
      "Epoch 10/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.1491 - accuracy: 0.9474 - val_loss: 0.2102 - val_accuracy: 0.9259\n",
      "Epoch 11/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.1411 - accuracy: 0.9498 - val_loss: 0.2079 - val_accuracy: 0.9326\n",
      "Epoch 12/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.1316 - accuracy: 0.9535 - val_loss: 0.1919 - val_accuracy: 0.9432\n",
      "Epoch 13/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.1253 - accuracy: 0.9559 - val_loss: 0.2114 - val_accuracy: 0.9326\n",
      "Epoch 14/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.1184 - accuracy: 0.9581 - val_loss: 0.1943 - val_accuracy: 0.9418\n",
      "Epoch 15/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.1087 - accuracy: 0.9605 - val_loss: 0.2060 - val_accuracy: 0.9360\n",
      "Epoch 16/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.1083 - accuracy: 0.9608 - val_loss: 0.2123 - val_accuracy: 0.9389\n",
      "Epoch 17/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.1006 - accuracy: 0.9637 - val_loss: 0.2021 - val_accuracy: 0.9413\n",
      "Epoch 18/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0942 - accuracy: 0.9669 - val_loss: 0.1938 - val_accuracy: 0.9398\n",
      "Epoch 19/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0874 - accuracy: 0.9685 - val_loss: 0.2247 - val_accuracy: 0.9379\n",
      "Epoch 20/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0857 - accuracy: 0.9692 - val_loss: 0.2247 - val_accuracy: 0.9456\n",
      "Epoch 21/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0841 - accuracy: 0.9688 - val_loss: 0.2460 - val_accuracy: 0.9293\n",
      "Epoch 22/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0763 - accuracy: 0.9721 - val_loss: 0.2149 - val_accuracy: 0.9418\n",
      "Epoch 23/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0690 - accuracy: 0.9743 - val_loss: 0.2147 - val_accuracy: 0.9451\n",
      "Epoch 24/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0735 - accuracy: 0.9733 - val_loss: 0.2039 - val_accuracy: 0.9442\n",
      "Epoch 25/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0657 - accuracy: 0.9761 - val_loss: 0.1874 - val_accuracy: 0.9490\n",
      "Epoch 26/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0659 - accuracy: 0.9750 - val_loss: 0.2090 - val_accuracy: 0.9437\n",
      "Epoch 27/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0659 - accuracy: 0.9772 - val_loss: 0.2181 - val_accuracy: 0.9437\n",
      "Epoch 28/250\n",
      "585/585 [==============================] - ETA: 0s - loss: 0.0641 - accuracy: 0.97 - 1s 2ms/step - loss: 0.0642 - accuracy: 0.9770 - val_loss: 0.2385 - val_accuracy: 0.9423\n",
      "Epoch 29/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0563 - accuracy: 0.9795 - val_loss: 0.2563 - val_accuracy: 0.9408\n",
      "Epoch 30/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0561 - accuracy: 0.9802 - val_loss: 0.2152 - val_accuracy: 0.9504\n",
      "Epoch 31/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0541 - accuracy: 0.9814 - val_loss: 0.2267 - val_accuracy: 0.9432\n",
      "Epoch 32/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0531 - accuracy: 0.9807 - val_loss: 0.2235 - val_accuracy: 0.9475\n",
      "Epoch 33/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0575 - accuracy: 0.9789 - val_loss: 0.2220 - val_accuracy: 0.9514\n",
      "Epoch 34/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0447 - accuracy: 0.9835 - val_loss: 0.2392 - val_accuracy: 0.9437\n",
      "Epoch 35/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0495 - accuracy: 0.9810 - val_loss: 0.2518 - val_accuracy: 0.9432\n",
      "Epoch 36/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0507 - accuracy: 0.9814 - val_loss: 0.2468 - val_accuracy: 0.9471\n",
      "Epoch 37/250\n",
      "585/585 [==============================] - ETA: 0s - loss: 0.0452 - accuracy: 0.98 - 1s 2ms/step - loss: 0.0454 - accuracy: 0.9834 - val_loss: 0.2412 - val_accuracy: 0.9471\n",
      "Epoch 38/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0413 - accuracy: 0.9845 - val_loss: 0.2581 - val_accuracy: 0.9485\n",
      "Epoch 39/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0411 - accuracy: 0.9849 - val_loss: 0.2682 - val_accuracy: 0.9437\n",
      "Epoch 40/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0448 - accuracy: 0.9848 - val_loss: 0.2597 - val_accuracy: 0.9490\n",
      "Epoch 41/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0419 - accuracy: 0.9858 - val_loss: 0.2435 - val_accuracy: 0.9490\n",
      "Epoch 42/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0445 - accuracy: 0.9844 - val_loss: 0.2948 - val_accuracy: 0.9423\n",
      "Epoch 43/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0439 - accuracy: 0.9835 - val_loss: 0.2330 - val_accuracy: 0.9485\n",
      "Epoch 44/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0353 - accuracy: 0.9864 - val_loss: 0.3140 - val_accuracy: 0.9451\n",
      "Epoch 45/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0418 - accuracy: 0.9854 - val_loss: 0.2622 - val_accuracy: 0.9514\n",
      "Epoch 46/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0404 - accuracy: 0.9847 - val_loss: 0.2548 - val_accuracy: 0.9466\n",
      "Epoch 47/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0341 - accuracy: 0.9873 - val_loss: 0.2450 - val_accuracy: 0.9514\n",
      "Epoch 48/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0288 - accuracy: 0.9900 - val_loss: 0.2972 - val_accuracy: 0.9427\n",
      "Epoch 49/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0372 - accuracy: 0.9871 - val_loss: 0.2580 - val_accuracy: 0.9509\n",
      "Epoch 50/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0419 - accuracy: 0.9840 - val_loss: 0.2706 - val_accuracy: 0.9500\n",
      "Epoch 51/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0411 - accuracy: 0.9854 - val_loss: 0.2588 - val_accuracy: 0.9500\n",
      "Epoch 52/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0309 - accuracy: 0.9886 - val_loss: 0.2979 - val_accuracy: 0.9394\n",
      "Epoch 53/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0339 - accuracy: 0.9876 - val_loss: 0.2740 - val_accuracy: 0.9524\n",
      "Epoch 54/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0264 - accuracy: 0.9897 - val_loss: 0.2860 - val_accuracy: 0.9471\n",
      "Epoch 55/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0374 - accuracy: 0.9865 - val_loss: 0.3050 - val_accuracy: 0.9485\n",
      "Epoch 56/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0262 - accuracy: 0.9899 - val_loss: 0.2821 - val_accuracy: 0.9495\n",
      "Epoch 57/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0282 - accuracy: 0.9893 - val_loss: 0.2686 - val_accuracy: 0.9500\n",
      "Epoch 58/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0359 - accuracy: 0.9865 - val_loss: 0.2932 - val_accuracy: 0.9519\n",
      "Epoch 59/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0318 - accuracy: 0.9894 - val_loss: 0.2853 - val_accuracy: 0.9485\n",
      "Epoch 60/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0238 - accuracy: 0.9916 - val_loss: 0.3079 - val_accuracy: 0.9471\n",
      "Epoch 61/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0275 - accuracy: 0.9903 - val_loss: 0.2636 - val_accuracy: 0.9495\n",
      "Epoch 62/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0308 - accuracy: 0.9889 - val_loss: 0.2932 - val_accuracy: 0.9432\n",
      "Epoch 63/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0264 - accuracy: 0.9905 - val_loss: 0.3062 - val_accuracy: 0.9504\n",
      "Epoch 64/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0275 - accuracy: 0.9901 - val_loss: 0.2919 - val_accuracy: 0.9456\n",
      "Epoch 65/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0265 - accuracy: 0.9896 - val_loss: 0.3283 - val_accuracy: 0.9466\n",
      "Epoch 66/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0283 - accuracy: 0.9893 - val_loss: 0.3070 - val_accuracy: 0.9480\n",
      "Epoch 67/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0239 - accuracy: 0.9911 - val_loss: 0.2904 - val_accuracy: 0.9504\n",
      "Epoch 68/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0292 - accuracy: 0.9899 - val_loss: 0.3030 - val_accuracy: 0.9480\n",
      "Epoch 69/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0227 - accuracy: 0.9919 - val_loss: 0.3232 - val_accuracy: 0.9442\n",
      "Epoch 70/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0298 - accuracy: 0.9887 - val_loss: 0.3125 - val_accuracy: 0.9514\n",
      "Epoch 71/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0257 - accuracy: 0.9912 - val_loss: 0.3209 - val_accuracy: 0.9500\n",
      "Epoch 72/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0208 - accuracy: 0.9920 - val_loss: 0.3691 - val_accuracy: 0.9475\n",
      "Epoch 73/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0316 - accuracy: 0.9883 - val_loss: 0.3196 - val_accuracy: 0.9442\n",
      "Epoch 74/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0237 - accuracy: 0.9914 - val_loss: 0.3316 - val_accuracy: 0.9495\n",
      "Epoch 75/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0137 - accuracy: 0.9957 - val_loss: 0.4492 - val_accuracy: 0.9394\n",
      "Epoch 76/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0337 - accuracy: 0.9884 - val_loss: 0.2809 - val_accuracy: 0.9524\n",
      "Epoch 77/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0241 - accuracy: 0.9918 - val_loss: 0.3377 - val_accuracy: 0.9524\n",
      "Epoch 78/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0319 - accuracy: 0.9891 - val_loss: 0.3174 - val_accuracy: 0.9543\n",
      "Epoch 79/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0181 - accuracy: 0.9938 - val_loss: 0.3182 - val_accuracy: 0.9485\n",
      "Epoch 80/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0235 - accuracy: 0.9919 - val_loss: 0.3204 - val_accuracy: 0.9514\n",
      "Epoch 81/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0207 - accuracy: 0.9926 - val_loss: 0.3694 - val_accuracy: 0.9451\n",
      "Epoch 82/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0285 - accuracy: 0.9898 - val_loss: 0.3322 - val_accuracy: 0.9514\n",
      "Epoch 83/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0166 - accuracy: 0.9938 - val_loss: 0.3141 - val_accuracy: 0.9504\n",
      "Epoch 84/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0220 - accuracy: 0.9922 - val_loss: 0.3907 - val_accuracy: 0.9437\n",
      "Epoch 85/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0273 - accuracy: 0.9903 - val_loss: 0.3206 - val_accuracy: 0.9466\n",
      "Epoch 86/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0174 - accuracy: 0.9933 - val_loss: 0.3138 - val_accuracy: 0.9471\n",
      "Epoch 87/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0274 - accuracy: 0.9907 - val_loss: 0.3724 - val_accuracy: 0.9471\n",
      "Epoch 88/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0244 - accuracy: 0.9914 - val_loss: 0.3567 - val_accuracy: 0.9480\n",
      "Epoch 89/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.3369 - val_accuracy: 0.9504\n",
      "Epoch 90/250\n",
      "585/585 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.99 - 1s 2ms/step - loss: 0.0127 - accuracy: 0.9950 - val_loss: 0.3195 - val_accuracy: 0.9528\n",
      "Epoch 91/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0218 - accuracy: 0.9927 - val_loss: 0.2847 - val_accuracy: 0.9509\n",
      "Epoch 92/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0285 - accuracy: 0.9909 - val_loss: 0.3212 - val_accuracy: 0.9524\n",
      "Epoch 93/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0228 - accuracy: 0.9915 - val_loss: 0.3479 - val_accuracy: 0.9514\n",
      "Epoch 94/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0189 - accuracy: 0.9939 - val_loss: 0.3490 - val_accuracy: 0.9418\n",
      "Epoch 95/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0237 - accuracy: 0.9911 - val_loss: 0.3500 - val_accuracy: 0.9519\n",
      "Epoch 96/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0143 - accuracy: 0.9949 - val_loss: 0.3378 - val_accuracy: 0.9509\n",
      "Epoch 97/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0170 - accuracy: 0.9940 - val_loss: 0.3444 - val_accuracy: 0.9432\n",
      "Epoch 98/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0240 - accuracy: 0.9925 - val_loss: 0.4077 - val_accuracy: 0.9418\n",
      "Epoch 99/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0240 - accuracy: 0.9920 - val_loss: 0.3367 - val_accuracy: 0.9562\n",
      "Epoch 100/250\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.0114 - accuracy: 0.9960 - val_loss: 0.3669 - val_accuracy: 0.9514\n",
      "Epoch 101/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0193 - accuracy: 0.9936 - val_loss: 0.3589 - val_accuracy: 0.9490\n",
      "Epoch 102/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0226 - accuracy: 0.9928 - val_loss: 0.3431 - val_accuracy: 0.9480\n",
      "Epoch 103/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0122 - accuracy: 0.9956 - val_loss: 0.3699 - val_accuracy: 0.9451\n",
      "Epoch 104/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0306 - accuracy: 0.9897 - val_loss: 0.3190 - val_accuracy: 0.9509\n",
      "Epoch 105/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0147 - accuracy: 0.9947 - val_loss: 0.3890 - val_accuracy: 0.9475\n",
      "Epoch 106/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0103 - accuracy: 0.9965 - val_loss: 0.3883 - val_accuracy: 0.9466\n",
      "Epoch 107/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0224 - accuracy: 0.9928 - val_loss: 0.3486 - val_accuracy: 0.9514\n",
      "Epoch 108/250\n",
      "585/585 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 0.99 - 1s 2ms/step - loss: 0.0227 - accuracy: 0.9924 - val_loss: 0.2946 - val_accuracy: 0.9504\n",
      "Epoch 109/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0134 - accuracy: 0.9953 - val_loss: 0.3146 - val_accuracy: 0.9543\n",
      "Epoch 110/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0151 - accuracy: 0.9946 - val_loss: 0.3787 - val_accuracy: 0.9432\n",
      "Epoch 111/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0184 - accuracy: 0.9943 - val_loss: 0.3608 - val_accuracy: 0.9500\n",
      "Epoch 112/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0140 - accuracy: 0.9951 - val_loss: 0.3578 - val_accuracy: 0.9475\n",
      "Epoch 113/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0297 - accuracy: 0.9907 - val_loss: 0.3691 - val_accuracy: 0.9447\n",
      "Epoch 114/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0195 - accuracy: 0.9937 - val_loss: 0.3228 - val_accuracy: 0.9562\n",
      "Epoch 115/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0118 - accuracy: 0.9957 - val_loss: 0.3766 - val_accuracy: 0.9528\n",
      "Epoch 116/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0131 - accuracy: 0.9947 - val_loss: 0.4156 - val_accuracy: 0.9514\n",
      "Epoch 117/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0203 - accuracy: 0.9937 - val_loss: 0.3832 - val_accuracy: 0.9500\n",
      "Epoch 118/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0204 - accuracy: 0.9929 - val_loss: 0.3718 - val_accuracy: 0.9442\n",
      "Epoch 119/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0133 - accuracy: 0.9950 - val_loss: 0.3459 - val_accuracy: 0.9471\n",
      "Epoch 120/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0216 - accuracy: 0.9926 - val_loss: 0.4264 - val_accuracy: 0.9423\n",
      "Epoch 121/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0155 - accuracy: 0.9950 - val_loss: 0.3899 - val_accuracy: 0.9471\n",
      "Epoch 122/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0181 - accuracy: 0.9943 - val_loss: 0.3617 - val_accuracy: 0.9519\n",
      "Epoch 123/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0178 - accuracy: 0.9938 - val_loss: 0.3427 - val_accuracy: 0.9538\n",
      "Epoch 124/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0211 - accuracy: 0.9924 - val_loss: 0.3667 - val_accuracy: 0.9475\n",
      "Epoch 125/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 0.3335 - val_accuracy: 0.9514\n",
      "Epoch 126/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0206 - accuracy: 0.9942 - val_loss: 0.3630 - val_accuracy: 0.9461\n",
      "Epoch 127/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0110 - accuracy: 0.9960 - val_loss: 0.3540 - val_accuracy: 0.9495\n",
      "Epoch 128/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0130 - accuracy: 0.9955 - val_loss: 0.4121 - val_accuracy: 0.9346\n",
      "Epoch 129/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0197 - accuracy: 0.9941 - val_loss: 0.3991 - val_accuracy: 0.9403\n",
      "Epoch 130/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 0.3352 - val_accuracy: 0.9528\n",
      "Epoch 131/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0069 - accuracy: 0.9973 - val_loss: 0.3583 - val_accuracy: 0.9548\n",
      "Epoch 132/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0289 - accuracy: 0.9918 - val_loss: 0.3605 - val_accuracy: 0.9466\n",
      "Epoch 133/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0168 - accuracy: 0.9948 - val_loss: 0.4074 - val_accuracy: 0.9432\n",
      "Epoch 134/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 0.4061 - val_accuracy: 0.9480\n",
      "Epoch 135/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0226 - accuracy: 0.9919 - val_loss: 0.3619 - val_accuracy: 0.9538\n",
      "Epoch 136/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.3770 - val_accuracy: 0.9514\n",
      "Epoch 137/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0186 - accuracy: 0.9936 - val_loss: 0.3827 - val_accuracy: 0.9528\n",
      "Epoch 138/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0161 - accuracy: 0.9943 - val_loss: 0.3842 - val_accuracy: 0.9533\n",
      "Epoch 139/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0135 - accuracy: 0.9955 - val_loss: 0.3777 - val_accuracy: 0.9548\n",
      "Epoch 140/250\n",
      "585/585 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 0.99 - 1s 2ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 0.4333 - val_accuracy: 0.9475\n",
      "Epoch 141/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0219 - accuracy: 0.9929 - val_loss: 0.3894 - val_accuracy: 0.9495\n",
      "Epoch 142/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0210 - accuracy: 0.9927 - val_loss: 0.3506 - val_accuracy: 0.9552\n",
      "Epoch 143/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.3482 - val_accuracy: 0.9524\n",
      "Epoch 144/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 0.3806 - val_accuracy: 0.9528\n",
      "Epoch 145/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0201 - accuracy: 0.9939 - val_loss: 0.4018 - val_accuracy: 0.9519\n",
      "Epoch 146/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0102 - accuracy: 0.9965 - val_loss: 0.3771 - val_accuracy: 0.9480\n",
      "Epoch 147/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0187 - accuracy: 0.9944 - val_loss: 0.3418 - val_accuracy: 0.9528\n",
      "Epoch 148/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.3734 - val_accuracy: 0.9538\n",
      "Epoch 149/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.3877 - val_accuracy: 0.9509\n",
      "Epoch 150/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0301 - accuracy: 0.9904 - val_loss: 0.3586 - val_accuracy: 0.9509\n",
      "Epoch 151/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.3769 - val_accuracy: 0.9524\n",
      "Epoch 152/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.4062 - val_accuracy: 0.9538\n",
      "Epoch 153/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.3869 - val_accuracy: 0.9557\n",
      "Epoch 154/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0196 - accuracy: 0.9937 - val_loss: 0.4404 - val_accuracy: 0.9437\n",
      "Epoch 155/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0191 - accuracy: 0.9929 - val_loss: 0.3846 - val_accuracy: 0.9485\n",
      "Epoch 156/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 0.3757 - val_accuracy: 0.9509\n",
      "Epoch 157/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0156 - accuracy: 0.9953 - val_loss: 0.3733 - val_accuracy: 0.9504\n",
      "Epoch 158/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 0.3520 - val_accuracy: 0.9509\n",
      "Epoch 159/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0070 - accuracy: 0.9974 - val_loss: 0.4285 - val_accuracy: 0.9466\n",
      "Epoch 160/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0230 - accuracy: 0.9925 - val_loss: 0.3850 - val_accuracy: 0.9485\n",
      "Epoch 161/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0174 - accuracy: 0.9945 - val_loss: 0.3552 - val_accuracy: 0.9567\n",
      "Epoch 162/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.3643 - val_accuracy: 0.9548\n",
      "Epoch 163/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 0.3763 - val_accuracy: 0.9548\n",
      "Epoch 164/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0195 - accuracy: 0.9937 - val_loss: 0.4031 - val_accuracy: 0.9461\n",
      "Epoch 165/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0113 - accuracy: 0.9958 - val_loss: 0.3962 - val_accuracy: 0.9475\n",
      "Epoch 166/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 0.3472 - val_accuracy: 0.9514\n",
      "Epoch 167/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0100 - accuracy: 0.9974 - val_loss: 0.4314 - val_accuracy: 0.9495\n",
      "Epoch 168/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0156 - accuracy: 0.9949 - val_loss: 0.3847 - val_accuracy: 0.9528\n",
      "Epoch 169/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 0.4196 - val_accuracy: 0.9538\n",
      "Epoch 170/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.3849 - val_accuracy: 0.9509\n",
      "Epoch 171/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 0.3857 - val_accuracy: 0.9504\n",
      "Epoch 172/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0188 - accuracy: 0.9951 - val_loss: 0.3712 - val_accuracy: 0.9533\n",
      "Epoch 173/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0061 - accuracy: 0.9978 - val_loss: 0.3392 - val_accuracy: 0.9581\n",
      "Epoch 174/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0076 - accuracy: 0.9973 - val_loss: 0.3651 - val_accuracy: 0.9514\n",
      "Epoch 175/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0197 - accuracy: 0.9933 - val_loss: 0.3941 - val_accuracy: 0.9552\n",
      "Epoch 176/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.3703 - val_accuracy: 0.9572\n",
      "Epoch 177/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.4274 - val_accuracy: 0.9456\n",
      "Epoch 178/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.3751 - val_accuracy: 0.9548\n",
      "Epoch 179/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.3531 - val_accuracy: 0.9552\n",
      "Epoch 180/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0116 - accuracy: 0.9965 - val_loss: 0.4274 - val_accuracy: 0.9504\n",
      "Epoch 181/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0189 - accuracy: 0.9933 - val_loss: 0.3917 - val_accuracy: 0.9552\n",
      "Epoch 182/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 0.4220 - val_accuracy: 0.9528\n",
      "Epoch 183/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.4082 - val_accuracy: 0.9500\n",
      "Epoch 184/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0132 - accuracy: 0.9960 - val_loss: 0.3895 - val_accuracy: 0.9528\n",
      "Epoch 185/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0059 - accuracy: 0.9979 - val_loss: 0.3898 - val_accuracy: 0.9538\n",
      "Epoch 186/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.4061 - val_accuracy: 0.9524\n",
      "Epoch 187/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0123 - accuracy: 0.9957 - val_loss: 0.3696 - val_accuracy: 0.9557\n",
      "Epoch 188/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0068 - accuracy: 0.9975 - val_loss: 0.4456 - val_accuracy: 0.9524\n",
      "Epoch 189/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0201 - accuracy: 0.9942 - val_loss: 0.3799 - val_accuracy: 0.9427\n",
      "Epoch 190/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 0.4105 - val_accuracy: 0.9543\n",
      "Epoch 191/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.3968 - val_accuracy: 0.9533\n",
      "Epoch 192/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0052 - accuracy: 0.9981 - val_loss: 0.3859 - val_accuracy: 0.9577\n",
      "Epoch 193/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.3759 - val_accuracy: 0.9504\n",
      "Epoch 194/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0098 - accuracy: 0.9965 - val_loss: 0.4008 - val_accuracy: 0.9519\n",
      "Epoch 195/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.3892 - val_accuracy: 0.9543\n",
      "Epoch 196/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 0.3882 - val_accuracy: 0.9519\n",
      "Epoch 197/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.4094 - val_accuracy: 0.9538\n",
      "Epoch 198/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.3951 - val_accuracy: 0.9475\n",
      "Epoch 199/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0147 - accuracy: 0.9949 - val_loss: 0.3916 - val_accuracy: 0.9480\n",
      "Epoch 200/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0163 - accuracy: 0.9940 - val_loss: 0.4131 - val_accuracy: 0.9490\n",
      "Epoch 201/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0174 - accuracy: 0.9955 - val_loss: 0.3980 - val_accuracy: 0.9538\n",
      "Epoch 202/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.4162 - val_accuracy: 0.9543\n",
      "Epoch 203/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.4860 - val_accuracy: 0.9475\n",
      "Epoch 204/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.3843 - val_accuracy: 0.9528\n",
      "Epoch 205/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.4206 - val_accuracy: 0.9538\n",
      "Epoch 206/250\n",
      "585/585 [==============================] - 2s 3ms/step - loss: 0.0143 - accuracy: 0.9957 - val_loss: 0.4928 - val_accuracy: 0.9509\n",
      "Epoch 207/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0206 - accuracy: 0.9941 - val_loss: 0.3649 - val_accuracy: 0.9533\n",
      "Epoch 208/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.3837 - val_accuracy: 0.9543\n",
      "Epoch 209/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.3771 - val_accuracy: 0.9557\n",
      "Epoch 210/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0070 - accuracy: 0.9985 - val_loss: 0.3825 - val_accuracy: 0.9552\n",
      "Epoch 211/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0264 - accuracy: 0.9930 - val_loss: 0.4307 - val_accuracy: 0.9528\n",
      "Epoch 212/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.4092 - val_accuracy: 0.9548\n",
      "Epoch 213/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.3798 - val_accuracy: 0.9528\n",
      "Epoch 214/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0117 - accuracy: 0.9956 - val_loss: 0.4236 - val_accuracy: 0.9471\n",
      "Epoch 215/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0090 - accuracy: 0.9966 - val_loss: 0.4015 - val_accuracy: 0.9504\n",
      "Epoch 216/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0094 - accuracy: 0.9974 - val_loss: 0.4326 - val_accuracy: 0.9519\n",
      "Epoch 217/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.3899 - val_accuracy: 0.9500\n",
      "Epoch 218/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 0.4388 - val_accuracy: 0.9528\n",
      "Epoch 219/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.4447 - val_accuracy: 0.9466\n",
      "Epoch 220/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.4275 - val_accuracy: 0.9490\n",
      "Epoch 221/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0137 - accuracy: 0.9958 - val_loss: 0.5512 - val_accuracy: 0.9437\n",
      "Epoch 222/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0142 - accuracy: 0.9961 - val_loss: 0.4020 - val_accuracy: 0.9543\n",
      "Epoch 223/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 0.4339 - val_accuracy: 0.9485\n",
      "Epoch 224/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0089 - accuracy: 0.9977 - val_loss: 0.4196 - val_accuracy: 0.9509\n",
      "Epoch 225/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 0.4180 - val_accuracy: 0.9519\n",
      "Epoch 226/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0114 - accuracy: 0.9970 - val_loss: 0.4225 - val_accuracy: 0.9495\n",
      "Epoch 227/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.4165 - val_accuracy: 0.9533\n",
      "Epoch 228/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.4039 - val_accuracy: 0.9552\n",
      "Epoch 229/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.4253 - val_accuracy: 0.9524\n",
      "Epoch 230/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0193 - accuracy: 0.9943 - val_loss: 0.4263 - val_accuracy: 0.9466\n",
      "Epoch 231/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.4242 - val_accuracy: 0.9533\n",
      "Epoch 232/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4423 - val_accuracy: 0.9509\n",
      "Epoch 233/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 0.4248 - val_accuracy: 0.9495\n",
      "Epoch 234/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0150 - accuracy: 0.9950 - val_loss: 0.4104 - val_accuracy: 0.9480\n",
      "Epoch 235/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0170 - accuracy: 0.9943 - val_loss: 0.4360 - val_accuracy: 0.9480\n",
      "Epoch 236/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 0.4407 - val_accuracy: 0.9413\n",
      "Epoch 237/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0049 - accuracy: 0.9981 - val_loss: 0.5268 - val_accuracy: 0.9475\n",
      "Epoch 238/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.4523 - val_accuracy: 0.9500\n",
      "Epoch 239/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0105 - accuracy: 0.9971 - val_loss: 0.4448 - val_accuracy: 0.9447\n",
      "Epoch 240/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.4303 - val_accuracy: 0.9466\n",
      "Epoch 241/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.4443 - val_accuracy: 0.9456\n",
      "Epoch 242/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0212 - accuracy: 0.9940 - val_loss: 0.4016 - val_accuracy: 0.9480\n",
      "Epoch 243/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.3944 - val_accuracy: 0.9548\n",
      "Epoch 244/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.4160 - val_accuracy: 0.9543\n",
      "Epoch 245/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.4948 - val_accuracy: 0.9485\n",
      "Epoch 246/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0164 - accuracy: 0.9948 - val_loss: 0.4832 - val_accuracy: 0.9466\n",
      "Epoch 247/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.4365 - val_accuracy: 0.9519\n",
      "Epoch 248/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.4392 - val_accuracy: 0.9538\n",
      "Epoch 249/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.4932 - val_accuracy: 0.9504\n",
      "Epoch 250/250\n",
      "585/585 [==============================] - 1s 2ms/step - loss: 0.0222 - accuracy: 0.9932 - val_loss: 0.4099 - val_accuracy: 0.9504\n"
     ]
    }
   ],
   "source": [
    "# Create the network using the Keras layers. (Use 512, 100 and 20 nodes for the hidden layers.)\n",
    "nn = Sequential()\n",
    "nn.add(InputLayer(input_shape=(187,)))\n",
    "nn.add(Dense(512, activation='relu', kernel_initializer='glorot_uniform'))\n",
    "nn.add(Dense(100, activation='relu', kernel_initializer='glorot_uniform'))\n",
    "nn.add(Dense(20, activation='relu', kernel_initializer='glorot_uniform'))\n",
    "nn.add(Dense(5, activation='softmax', kernel_initializer='glorot_uniform'))\n",
    "\n",
    "# early_stop = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "\n",
    "# Compile and train the network. (Do not forget to expand the training labels into multiple columns.)\n",
    "y_train_target = to_categorical(y_train)\n",
    "y_test_target = to_categorical(y_test)\n",
    "\n",
    "nn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = nn.fit(X_train, y_train_target, validation_split=0.1, epochs=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate your neural network with the test data. You need to achieve 90+% test accuracy for full credit. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 1ms/step - loss: 0.4182 - accuracy: 0.9498\n",
      "[0.41821160912513733, 0.9497618079185486]\n",
      "0.9497618016457341\n",
      "[[774  27   4   5   4]\n",
      " [ 16 192   4   2   1]\n",
      " [ 18   3 539   9   2]\n",
      " [  3   0   6  57   0]\n",
      " [  5   2   4   1 631]]\n"
     ]
    }
   ],
   "source": [
    "# Get the predictions and convert the multicolumn array into class predictions.\n",
    "print(nn.evaluate(X_test, y_test_target))\n",
    "y_pred = np.argmax(nn.predict(X_test), axis=1)\n",
    "\n",
    "\n",
    "# Plot the confusion matrix and print the final accuracy.\n",
    "print(accuracy_score(y_pred, y_test))\n",
    "print(confusion_matrix(y_pred, y_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After the feed-forward neural network, train a convolutional neural network (CNN) on the same data. (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.7418 - accuracy: 0.7198 - val_loss: 0.4253 - val_accuracy: 0.8619\n",
      "Epoch 2/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.3620 - accuracy: 0.8810 - val_loss: 0.4331 - val_accuracy: 0.8450\n",
      "Epoch 3/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.2978 - accuracy: 0.9038 - val_loss: 0.3187 - val_accuracy: 0.9004\n",
      "Epoch 4/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.2546 - accuracy: 0.9163 - val_loss: 0.3454 - val_accuracy: 0.8826\n",
      "Epoch 5/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.2328 - accuracy: 0.9232 - val_loss: 0.2420 - val_accuracy: 0.9216\n",
      "Epoch 6/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.2144 - accuracy: 0.9279 - val_loss: 0.2217 - val_accuracy: 0.9312\n",
      "Epoch 7/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.2058 - accuracy: 0.9320 - val_loss: 0.2769 - val_accuracy: 0.9105\n",
      "Epoch 8/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.1899 - accuracy: 0.9367 - val_loss: 0.2495 - val_accuracy: 0.9259\n",
      "Epoch 9/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.1777 - accuracy: 0.9395 - val_loss: 0.2075 - val_accuracy: 0.9331\n",
      "Epoch 10/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.1719 - accuracy: 0.9419 - val_loss: 0.1748 - val_accuracy: 0.9423\n",
      "Epoch 11/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.1596 - accuracy: 0.9460 - val_loss: 0.1796 - val_accuracy: 0.9355\n",
      "Epoch 12/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.1565 - accuracy: 0.9454 - val_loss: 0.1910 - val_accuracy: 0.9355\n",
      "Epoch 13/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.1466 - accuracy: 0.9487 - val_loss: 0.1660 - val_accuracy: 0.9456\n",
      "Epoch 14/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.1430 - accuracy: 0.9507 - val_loss: 0.1798 - val_accuracy: 0.9403\n",
      "Epoch 15/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.1310 - accuracy: 0.9554 - val_loss: 0.1800 - val_accuracy: 0.9418\n",
      "Epoch 16/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.1296 - accuracy: 0.9547 - val_loss: 0.1572 - val_accuracy: 0.9500\n",
      "Epoch 17/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.1252 - accuracy: 0.9554 - val_loss: 0.1862 - val_accuracy: 0.9317\n",
      "Epoch 18/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.1208 - accuracy: 0.9570 - val_loss: 0.1382 - val_accuracy: 0.9538\n",
      "Epoch 19/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.1124 - accuracy: 0.9607 - val_loss: 0.1645 - val_accuracy: 0.9418\n",
      "Epoch 20/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.1091 - accuracy: 0.9614 - val_loss: 0.1637 - val_accuracy: 0.9461\n",
      "Epoch 21/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.1023 - accuracy: 0.9642 - val_loss: 0.1542 - val_accuracy: 0.9533\n",
      "Epoch 22/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.1022 - accuracy: 0.9640 - val_loss: 0.1441 - val_accuracy: 0.9519\n",
      "Epoch 23/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0950 - accuracy: 0.9656 - val_loss: 0.1641 - val_accuracy: 0.9519\n",
      "Epoch 24/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0964 - accuracy: 0.9636 - val_loss: 0.1626 - val_accuracy: 0.9528\n",
      "Epoch 25/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0906 - accuracy: 0.9668 - val_loss: 0.1402 - val_accuracy: 0.9557\n",
      "Epoch 26/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0891 - accuracy: 0.9680 - val_loss: 0.2202 - val_accuracy: 0.9331\n",
      "Epoch 27/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0851 - accuracy: 0.9682 - val_loss: 0.1473 - val_accuracy: 0.9538\n",
      "Epoch 28/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0796 - accuracy: 0.9713 - val_loss: 0.1480 - val_accuracy: 0.9490\n",
      "Epoch 29/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0769 - accuracy: 0.9718 - val_loss: 0.1428 - val_accuracy: 0.9543\n",
      "Epoch 30/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0741 - accuracy: 0.9712 - val_loss: 0.1555 - val_accuracy: 0.9519\n",
      "Epoch 31/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0720 - accuracy: 0.9733 - val_loss: 0.1435 - val_accuracy: 0.9567\n",
      "Epoch 32/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0656 - accuracy: 0.9749 - val_loss: 0.1928 - val_accuracy: 0.9418\n",
      "Epoch 33/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0643 - accuracy: 0.9763 - val_loss: 0.1527 - val_accuracy: 0.9533\n",
      "Epoch 34/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0687 - accuracy: 0.9738 - val_loss: 0.1553 - val_accuracy: 0.9480\n",
      "Epoch 35/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0606 - accuracy: 0.9772 - val_loss: 0.1551 - val_accuracy: 0.9577\n",
      "Epoch 36/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0560 - accuracy: 0.9783 - val_loss: 0.2011 - val_accuracy: 0.9480\n",
      "Epoch 37/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0588 - accuracy: 0.9781 - val_loss: 0.1641 - val_accuracy: 0.9533\n",
      "Epoch 38/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0508 - accuracy: 0.9807 - val_loss: 0.1620 - val_accuracy: 0.9514\n",
      "Epoch 39/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0561 - accuracy: 0.9794 - val_loss: 0.2013 - val_accuracy: 0.9451\n",
      "Epoch 40/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0520 - accuracy: 0.9807 - val_loss: 0.1939 - val_accuracy: 0.9490\n",
      "Epoch 41/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0510 - accuracy: 0.9815 - val_loss: 0.1950 - val_accuracy: 0.9509\n",
      "Epoch 42/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0402 - accuracy: 0.9846 - val_loss: 0.2052 - val_accuracy: 0.9577\n",
      "Epoch 43/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0453 - accuracy: 0.9826 - val_loss: 0.2067 - val_accuracy: 0.9548\n",
      "Epoch 44/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0453 - accuracy: 0.9832 - val_loss: 0.2597 - val_accuracy: 0.9398\n",
      "Epoch 45/250\n",
      "585/585 [==============================] - ETA: 0s - loss: 0.0464 - accuracy: 0.98 - 4s 6ms/step - loss: 0.0466 - accuracy: 0.9823 - val_loss: 0.2810 - val_accuracy: 0.9389\n",
      "Epoch 46/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0429 - accuracy: 0.9838 - val_loss: 0.2172 - val_accuracy: 0.9475\n",
      "Epoch 47/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0392 - accuracy: 0.9853 - val_loss: 0.2317 - val_accuracy: 0.9528\n",
      "Epoch 48/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0430 - accuracy: 0.9837 - val_loss: 0.1862 - val_accuracy: 0.9509\n",
      "Epoch 49/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0390 - accuracy: 0.9844 - val_loss: 0.2162 - val_accuracy: 0.9562\n",
      "Epoch 50/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0398 - accuracy: 0.9857 - val_loss: 0.1969 - val_accuracy: 0.9562\n",
      "Epoch 51/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0363 - accuracy: 0.9866 - val_loss: 0.2122 - val_accuracy: 0.9528\n",
      "Epoch 52/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0370 - accuracy: 0.9868 - val_loss: 0.2116 - val_accuracy: 0.9466\n",
      "Epoch 53/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0394 - accuracy: 0.9851 - val_loss: 0.2136 - val_accuracy: 0.9581\n",
      "Epoch 54/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0355 - accuracy: 0.9851 - val_loss: 0.1771 - val_accuracy: 0.9557\n",
      "Epoch 55/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0271 - accuracy: 0.9903 - val_loss: 0.2670 - val_accuracy: 0.9524\n",
      "Epoch 56/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0348 - accuracy: 0.9873 - val_loss: 0.1935 - val_accuracy: 0.9591\n",
      "Epoch 57/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0350 - accuracy: 0.9864 - val_loss: 0.2039 - val_accuracy: 0.9557\n",
      "Epoch 58/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0355 - accuracy: 0.9871 - val_loss: 0.2190 - val_accuracy: 0.9557\n",
      "Epoch 59/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0285 - accuracy: 0.9887 - val_loss: 0.1892 - val_accuracy: 0.9548\n",
      "Epoch 60/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0316 - accuracy: 0.9875 - val_loss: 0.1802 - val_accuracy: 0.9504\n",
      "Epoch 61/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0333 - accuracy: 0.9881 - val_loss: 0.1996 - val_accuracy: 0.9591\n",
      "Epoch 62/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0313 - accuracy: 0.9887 - val_loss: 0.2213 - val_accuracy: 0.9514\n",
      "Epoch 63/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0291 - accuracy: 0.9889 - val_loss: 0.2134 - val_accuracy: 0.9504\n",
      "Epoch 64/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0295 - accuracy: 0.9881 - val_loss: 0.1975 - val_accuracy: 0.9572\n",
      "Epoch 65/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0262 - accuracy: 0.9904 - val_loss: 0.2109 - val_accuracy: 0.9572\n",
      "Epoch 66/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0322 - accuracy: 0.9878 - val_loss: 0.2621 - val_accuracy: 0.9451\n",
      "Epoch 67/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0234 - accuracy: 0.9915 - val_loss: 0.2165 - val_accuracy: 0.9567\n",
      "Epoch 68/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0293 - accuracy: 0.9891 - val_loss: 0.1964 - val_accuracy: 0.9562\n",
      "Epoch 69/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0319 - accuracy: 0.9873 - val_loss: 0.1944 - val_accuracy: 0.9538\n",
      "Epoch 70/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0175 - accuracy: 0.9940 - val_loss: 0.2729 - val_accuracy: 0.9509\n",
      "Epoch 71/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0318 - accuracy: 0.9883 - val_loss: 0.2121 - val_accuracy: 0.9572\n",
      "Epoch 72/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0241 - accuracy: 0.9912 - val_loss: 0.2288 - val_accuracy: 0.9519\n",
      "Epoch 73/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0192 - accuracy: 0.9933 - val_loss: 0.2492 - val_accuracy: 0.9500\n",
      "Epoch 74/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0328 - accuracy: 0.9889 - val_loss: 0.2180 - val_accuracy: 0.9562\n",
      "Epoch 75/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0237 - accuracy: 0.9905 - val_loss: 0.2016 - val_accuracy: 0.9548\n",
      "Epoch 76/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0206 - accuracy: 0.9928 - val_loss: 0.2296 - val_accuracy: 0.9620\n",
      "Epoch 77/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0292 - accuracy: 0.9899 - val_loss: 0.2362 - val_accuracy: 0.9500\n",
      "Epoch 78/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0183 - accuracy: 0.9931 - val_loss: 0.2432 - val_accuracy: 0.9596\n",
      "Epoch 79/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0270 - accuracy: 0.9892 - val_loss: 0.2283 - val_accuracy: 0.9552\n",
      "Epoch 80/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0248 - accuracy: 0.9906 - val_loss: 0.2207 - val_accuracy: 0.9557\n",
      "Epoch 81/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0244 - accuracy: 0.9919 - val_loss: 0.2078 - val_accuracy: 0.9586\n",
      "Epoch 82/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0208 - accuracy: 0.9922 - val_loss: 0.2237 - val_accuracy: 0.9548\n",
      "Epoch 83/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0171 - accuracy: 0.9938 - val_loss: 0.2718 - val_accuracy: 0.9495\n",
      "Epoch 84/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0226 - accuracy: 0.9913 - val_loss: 0.2345 - val_accuracy: 0.9543\n",
      "Epoch 85/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0246 - accuracy: 0.9915 - val_loss: 0.2749 - val_accuracy: 0.9480\n",
      "Epoch 86/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0199 - accuracy: 0.9924 - val_loss: 0.2676 - val_accuracy: 0.9519\n",
      "Epoch 87/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0208 - accuracy: 0.9926 - val_loss: 0.2185 - val_accuracy: 0.9552\n",
      "Epoch 88/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0225 - accuracy: 0.9920 - val_loss: 0.2336 - val_accuracy: 0.9605\n",
      "Epoch 89/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 0.2677 - val_accuracy: 0.9639\n",
      "Epoch 90/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0331 - accuracy: 0.9887 - val_loss: 0.2442 - val_accuracy: 0.9543\n",
      "Epoch 91/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0159 - accuracy: 0.9938 - val_loss: 0.2484 - val_accuracy: 0.9596\n",
      "Epoch 92/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0187 - accuracy: 0.9930 - val_loss: 0.2350 - val_accuracy: 0.9524\n",
      "Epoch 93/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0222 - accuracy: 0.9920 - val_loss: 0.2493 - val_accuracy: 0.9552\n",
      "Epoch 94/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0168 - accuracy: 0.9931 - val_loss: 0.2778 - val_accuracy: 0.9548\n",
      "Epoch 95/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0256 - accuracy: 0.9921 - val_loss: 0.2495 - val_accuracy: 0.9466\n",
      "Epoch 96/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0161 - accuracy: 0.9943 - val_loss: 0.2693 - val_accuracy: 0.9519\n",
      "Epoch 97/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0174 - accuracy: 0.9935 - val_loss: 0.2684 - val_accuracy: 0.9581\n",
      "Epoch 98/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0199 - accuracy: 0.9930 - val_loss: 0.3227 - val_accuracy: 0.9485\n",
      "Epoch 99/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0251 - accuracy: 0.9920 - val_loss: 0.2162 - val_accuracy: 0.9562\n",
      "Epoch 100/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0153 - accuracy: 0.9942 - val_loss: 0.3024 - val_accuracy: 0.9562\n",
      "Epoch 101/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0228 - accuracy: 0.9922 - val_loss: 0.2103 - val_accuracy: 0.9572\n",
      "Epoch 102/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.2757 - val_accuracy: 0.9509\n",
      "Epoch 103/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0225 - accuracy: 0.9918 - val_loss: 0.2558 - val_accuracy: 0.9485\n",
      "Epoch 104/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0163 - accuracy: 0.9935 - val_loss: 0.2368 - val_accuracy: 0.9620\n",
      "Epoch 105/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0063 - accuracy: 0.9977 - val_loss: 0.2836 - val_accuracy: 0.9567\n",
      "Epoch 106/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0185 - accuracy: 0.9934 - val_loss: 0.2891 - val_accuracy: 0.9577\n",
      "Epoch 107/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0232 - accuracy: 0.9927 - val_loss: 0.2455 - val_accuracy: 0.9577\n",
      "Epoch 108/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0175 - accuracy: 0.9934 - val_loss: 0.3117 - val_accuracy: 0.9519\n",
      "Epoch 109/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0149 - accuracy: 0.9945 - val_loss: 0.3059 - val_accuracy: 0.9490\n",
      "Epoch 110/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0204 - accuracy: 0.9930 - val_loss: 0.2481 - val_accuracy: 0.9572\n",
      "Epoch 111/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0224 - accuracy: 0.9923 - val_loss: 0.2726 - val_accuracy: 0.9610\n",
      "Epoch 112/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 0.3119 - val_accuracy: 0.9533\n",
      "Epoch 113/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0222 - accuracy: 0.9927 - val_loss: 0.2353 - val_accuracy: 0.9519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0160 - accuracy: 0.9949 - val_loss: 0.2348 - val_accuracy: 0.9572\n",
      "Epoch 115/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0226 - accuracy: 0.9922 - val_loss: 0.2552 - val_accuracy: 0.9567\n",
      "Epoch 116/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0137 - accuracy: 0.9947 - val_loss: 0.3014 - val_accuracy: 0.9524\n",
      "Epoch 117/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0142 - accuracy: 0.9952 - val_loss: 0.2336 - val_accuracy: 0.9538\n",
      "Epoch 118/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0128 - accuracy: 0.9952 - val_loss: 0.2674 - val_accuracy: 0.9543\n",
      "Epoch 119/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0196 - accuracy: 0.9929 - val_loss: 0.2395 - val_accuracy: 0.9524\n",
      "Epoch 120/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0135 - accuracy: 0.9947 - val_loss: 0.2690 - val_accuracy: 0.9577\n",
      "Epoch 121/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0180 - accuracy: 0.9940 - val_loss: 0.2631 - val_accuracy: 0.9471\n",
      "Epoch 122/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0176 - accuracy: 0.9937 - val_loss: 0.2739 - val_accuracy: 0.9581\n",
      "Epoch 123/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0095 - accuracy: 0.9965 - val_loss: 0.3004 - val_accuracy: 0.9519\n",
      "Epoch 124/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0200 - accuracy: 0.9927 - val_loss: 0.2414 - val_accuracy: 0.9577\n",
      "Epoch 125/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0132 - accuracy: 0.9955 - val_loss: 0.2680 - val_accuracy: 0.9591\n",
      "Epoch 126/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0111 - accuracy: 0.9960 - val_loss: 0.2567 - val_accuracy: 0.9577\n",
      "Epoch 127/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0176 - accuracy: 0.9941 - val_loss: 0.2542 - val_accuracy: 0.9548\n",
      "Epoch 128/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0203 - accuracy: 0.9926 - val_loss: 0.2544 - val_accuracy: 0.9533\n",
      "Epoch 129/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0103 - accuracy: 0.9961 - val_loss: 0.2520 - val_accuracy: 0.9567\n",
      "Epoch 130/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0212 - accuracy: 0.9927 - val_loss: 0.2682 - val_accuracy: 0.9552\n",
      "Epoch 131/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0090 - accuracy: 0.9965 - val_loss: 0.2885 - val_accuracy: 0.9528\n",
      "Epoch 132/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0164 - accuracy: 0.9937 - val_loss: 0.2707 - val_accuracy: 0.9528\n",
      "Epoch 133/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0117 - accuracy: 0.9955 - val_loss: 0.2628 - val_accuracy: 0.9577\n",
      "Epoch 134/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0178 - accuracy: 0.9940 - val_loss: 0.2540 - val_accuracy: 0.9543\n",
      "Epoch 135/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0116 - accuracy: 0.9958 - val_loss: 0.2861 - val_accuracy: 0.9562\n",
      "Epoch 136/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.3473 - val_accuracy: 0.9572\n",
      "Epoch 137/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0188 - accuracy: 0.9941 - val_loss: 0.2836 - val_accuracy: 0.9533\n",
      "Epoch 138/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0074 - accuracy: 0.9972 - val_loss: 0.3056 - val_accuracy: 0.9572\n",
      "Epoch 139/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0189 - accuracy: 0.9940 - val_loss: 0.2540 - val_accuracy: 0.9557\n",
      "Epoch 140/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 0.3221 - val_accuracy: 0.9519\n",
      "Epoch 141/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0184 - accuracy: 0.9933 - val_loss: 0.2956 - val_accuracy: 0.9572\n",
      "Epoch 142/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.2663 - val_accuracy: 0.9548\n",
      "Epoch 143/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0072 - accuracy: 0.9973 - val_loss: 0.2924 - val_accuracy: 0.9581\n",
      "Epoch 144/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0045 - accuracy: 0.9983 - val_loss: 0.3960 - val_accuracy: 0.9519\n",
      "Epoch 145/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0266 - accuracy: 0.9909 - val_loss: 0.2724 - val_accuracy: 0.9610\n",
      "Epoch 146/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0141 - accuracy: 0.9947 - val_loss: 0.3212 - val_accuracy: 0.9591\n",
      "Epoch 147/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 0.2504 - val_accuracy: 0.9591\n",
      "Epoch 148/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.2963 - val_accuracy: 0.9581\n",
      "Epoch 149/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 0.2648 - val_accuracy: 0.9591\n",
      "Epoch 150/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.2498 - val_accuracy: 0.9586\n",
      "Epoch 151/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0191 - accuracy: 0.9932 - val_loss: 0.2604 - val_accuracy: 0.9567\n",
      "Epoch 152/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.2681 - val_accuracy: 0.9601\n",
      "Epoch 153/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 0.2870 - val_accuracy: 0.9562\n",
      "Epoch 154/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0116 - accuracy: 0.9958 - val_loss: 0.2600 - val_accuracy: 0.9572\n",
      "Epoch 155/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0135 - accuracy: 0.9952 - val_loss: 0.3044 - val_accuracy: 0.9572\n",
      "Epoch 156/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0093 - accuracy: 0.9964 - val_loss: 0.3262 - val_accuracy: 0.9591\n",
      "Epoch 157/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0204 - accuracy: 0.9940 - val_loss: 0.2876 - val_accuracy: 0.9572\n",
      "Epoch 158/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.3081 - val_accuracy: 0.9567\n",
      "Epoch 159/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0163 - accuracy: 0.9950 - val_loss: 0.2770 - val_accuracy: 0.9572\n",
      "Epoch 160/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0076 - accuracy: 0.9971 - val_loss: 0.2537 - val_accuracy: 0.9605\n",
      "Epoch 161/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0145 - accuracy: 0.9955 - val_loss: 0.3358 - val_accuracy: 0.9591\n",
      "Epoch 162/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0149 - accuracy: 0.9942 - val_loss: 0.3044 - val_accuracy: 0.9572\n",
      "Epoch 163/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 0.2993 - val_accuracy: 0.9581\n",
      "Epoch 164/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0124 - accuracy: 0.9954 - val_loss: 0.3324 - val_accuracy: 0.9572\n",
      "Epoch 165/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0099 - accuracy: 0.9965 - val_loss: 0.2773 - val_accuracy: 0.9586\n",
      "Epoch 166/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0125 - accuracy: 0.9965 - val_loss: 0.2624 - val_accuracy: 0.9557\n",
      "Epoch 167/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0219 - accuracy: 0.9939 - val_loss: 0.2891 - val_accuracy: 0.9528\n",
      "Epoch 168/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.3019 - val_accuracy: 0.9596\n",
      "Epoch 169/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 0.2810 - val_accuracy: 0.9562\n",
      "Epoch 170/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.3121 - val_accuracy: 0.9562\n",
      "Epoch 171/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0110 - accuracy: 0.9958 - val_loss: 0.2886 - val_accuracy: 0.9572\n",
      "Epoch 172/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0165 - accuracy: 0.9943 - val_loss: 0.2897 - val_accuracy: 0.9548\n",
      "Epoch 173/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.2468 - val_accuracy: 0.9577\n",
      "Epoch 174/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0050 - accuracy: 0.9980 - val_loss: 0.3168 - val_accuracy: 0.9543\n",
      "Epoch 175/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 0.2802 - val_accuracy: 0.9552\n",
      "Epoch 176/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0146 - accuracy: 0.9950 - val_loss: 0.2758 - val_accuracy: 0.9639\n",
      "Epoch 177/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0177 - accuracy: 0.9947 - val_loss: 0.2727 - val_accuracy: 0.9586\n",
      "Epoch 178/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.3127 - val_accuracy: 0.9591\n",
      "Epoch 179/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0114 - accuracy: 0.9958 - val_loss: 0.2589 - val_accuracy: 0.9591\n",
      "Epoch 180/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.2926 - val_accuracy: 0.9605\n",
      "Epoch 181/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 0.2484 - val_accuracy: 0.9548\n",
      "Epoch 182/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 0.2818 - val_accuracy: 0.9538\n",
      "Epoch 183/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.3150 - val_accuracy: 0.9548\n",
      "Epoch 184/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 0.4022 - val_accuracy: 0.9519\n",
      "Epoch 185/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0181 - accuracy: 0.9938 - val_loss: 0.2880 - val_accuracy: 0.9524\n",
      "Epoch 186/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.3186 - val_accuracy: 0.9577\n",
      "Epoch 187/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.3068 - val_accuracy: 0.9591\n",
      "Epoch 188/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0198 - accuracy: 0.9937 - val_loss: 0.3144 - val_accuracy: 0.9495\n",
      "Epoch 189/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.2451 - val_accuracy: 0.9601\n",
      "Epoch 190/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.3225 - val_accuracy: 0.9500\n",
      "Epoch 191/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 0.3000 - val_accuracy: 0.9581\n",
      "Epoch 192/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0095 - accuracy: 0.9973 - val_loss: 0.3154 - val_accuracy: 0.9605\n",
      "Epoch 193/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0125 - accuracy: 0.9966 - val_loss: 0.2663 - val_accuracy: 0.9620\n",
      "Epoch 194/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.3012 - val_accuracy: 0.9586\n",
      "Epoch 195/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0093 - accuracy: 0.9964 - val_loss: 0.3081 - val_accuracy: 0.9620\n",
      "Epoch 196/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0181 - accuracy: 0.9946 - val_loss: 0.2855 - val_accuracy: 0.9552\n",
      "Epoch 197/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.3272 - val_accuracy: 0.9615\n",
      "Epoch 198/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0124 - accuracy: 0.9955 - val_loss: 0.2836 - val_accuracy: 0.9605\n",
      "Epoch 199/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0047 - accuracy: 0.9983 - val_loss: 0.3929 - val_accuracy: 0.9533\n",
      "Epoch 200/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 0.2958 - val_accuracy: 0.9581\n",
      "Epoch 201/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.3371 - val_accuracy: 0.9557\n",
      "Epoch 202/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0151 - accuracy: 0.9945 - val_loss: 0.2981 - val_accuracy: 0.9581\n",
      "Epoch 203/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.2786 - val_accuracy: 0.9543\n",
      "Epoch 204/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0081 - accuracy: 0.9968 - val_loss: 0.2953 - val_accuracy: 0.9605\n",
      "Epoch 205/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0152 - accuracy: 0.9955 - val_loss: 0.2699 - val_accuracy: 0.9562\n",
      "Epoch 206/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.2907 - val_accuracy: 0.9562\n",
      "Epoch 207/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.3321 - val_accuracy: 0.9572\n",
      "Epoch 208/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0162 - accuracy: 0.9950 - val_loss: 0.3172 - val_accuracy: 0.9572\n",
      "Epoch 209/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.2926 - val_accuracy: 0.9524\n",
      "Epoch 210/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0099 - accuracy: 0.9971 - val_loss: 0.2928 - val_accuracy: 0.9591\n",
      "Epoch 211/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.3260 - val_accuracy: 0.9591\n",
      "Epoch 212/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.3510 - val_accuracy: 0.9490\n",
      "Epoch 213/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0170 - accuracy: 0.9942 - val_loss: 0.2706 - val_accuracy: 0.9577\n",
      "Epoch 214/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.3117 - val_accuracy: 0.9601\n",
      "Epoch 215/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0156 - accuracy: 0.9947 - val_loss: 0.2806 - val_accuracy: 0.9572\n",
      "Epoch 216/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.3196 - val_accuracy: 0.9562\n",
      "Epoch 217/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.2796 - val_accuracy: 0.9596\n",
      "Epoch 218/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.3037 - val_accuracy: 0.9572\n",
      "Epoch 219/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 0.2869 - val_accuracy: 0.9557\n",
      "Epoch 220/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0063 - accuracy: 0.9975 - val_loss: 0.2846 - val_accuracy: 0.9567\n",
      "Epoch 221/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 0.2880 - val_accuracy: 0.9586\n",
      "Epoch 222/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0081 - accuracy: 0.9970 - val_loss: 0.2970 - val_accuracy: 0.9649\n",
      "Epoch 223/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.2792 - val_accuracy: 0.9577\n",
      "Epoch 224/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 0.2466 - val_accuracy: 0.9620\n",
      "Epoch 225/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.2748 - val_accuracy: 0.9581\n",
      "Epoch 226/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.3055 - val_accuracy: 0.9615\n",
      "Epoch 227/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.3799 - val_accuracy: 0.9495\n",
      "Epoch 228/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0199 - accuracy: 0.9942 - val_loss: 0.2691 - val_accuracy: 0.9572\n",
      "Epoch 229/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.3069 - val_accuracy: 0.9620\n",
      "Epoch 230/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.2276 - val_accuracy: 0.9634\n",
      "Epoch 231/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.3078 - val_accuracy: 0.9524\n",
      "Epoch 232/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.2638 - val_accuracy: 0.9577\n",
      "Epoch 233/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.2996 - val_accuracy: 0.9586\n",
      "Epoch 234/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.3179 - val_accuracy: 0.9577\n",
      "Epoch 235/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0135 - accuracy: 0.9961 - val_loss: 0.2554 - val_accuracy: 0.9596\n",
      "Epoch 236/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.2994 - val_accuracy: 0.9581\n",
      "Epoch 237/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.3360 - val_accuracy: 0.9591\n",
      "Epoch 238/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0134 - accuracy: 0.9956 - val_loss: 0.3221 - val_accuracy: 0.9596\n",
      "Epoch 239/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.3147 - val_accuracy: 0.9581\n",
      "Epoch 240/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0160 - accuracy: 0.9945 - val_loss: 0.3262 - val_accuracy: 0.9533\n",
      "Epoch 241/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0137 - accuracy: 0.9959 - val_loss: 0.2899 - val_accuracy: 0.9548\n",
      "Epoch 242/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.3494 - val_accuracy: 0.9548\n",
      "Epoch 243/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0129 - accuracy: 0.9960 - val_loss: 0.2785 - val_accuracy: 0.9586\n",
      "Epoch 244/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0078 - accuracy: 0.9980 - val_loss: 0.2511 - val_accuracy: 0.9591\n",
      "Epoch 245/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.2683 - val_accuracy: 0.9605\n",
      "Epoch 246/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.2991 - val_accuracy: 0.9596\n",
      "Epoch 247/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.3127 - val_accuracy: 0.9581\n",
      "Epoch 248/250\n",
      "585/585 [==============================] - 4s 6ms/step - loss: 0.0177 - accuracy: 0.9949 - val_loss: 0.2812 - val_accuracy: 0.9552\n",
      "Epoch 249/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 0.3355 - val_accuracy: 0.9504\n",
      "Epoch 250/250\n",
      "585/585 [==============================] - 4s 7ms/step - loss: 0.0168 - accuracy: 0.9959 - val_loss: 0.2716 - val_accuracy: 0.9601\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2d20a83c0d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add a dimension to each sequence\n",
    "X_train = np.array(X_train).reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = np.array(X_test).reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# Create the CNN using the Keras layers. (Hint: You can keep the fully-connected part the same as the previous network.)\n",
    "cnn = Sequential()\n",
    "cnn.add(Conv1D(32, 3, activation='relu', input_shape=(187,1)))\n",
    "cnn.add(MaxPooling1D(pool_size=5))\n",
    "\n",
    "cnn.add(Conv1D(32, 3, activation='relu'))\n",
    "cnn.add(MaxPooling1D(pool_size=5))\n",
    "        \n",
    "cnn.add(Conv1D(64, 3, activation='relu'))\n",
    "cnn.add(MaxPooling1D(pool_size=5))\n",
    "        \n",
    "cnn.add(Flatten())\n",
    "        \n",
    "cnn.add(Dense(activation='relu', units=512))\n",
    "cnn.add(Dense(activation='relu', units=100))\n",
    "cnn.add(Dense(activation='relu', units=20))\n",
    "cnn.add(Dense(activation='softmax', units=5))\n",
    "\n",
    "\n",
    "# Compile and train the network.\n",
    "\n",
    "\n",
    "cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "# early = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "cnn.fit(X_train, y_train_target, validation_split=0.1, epochs=250)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate your CNN with the test data. You need to beat the feed-forward network accuracy for full credit. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3125 - accuracy: 0.9606\n",
      "[0.3124532997608185, 0.9605889916419983]\n",
      "0.9605889995669121\n",
      "[[776  19   3   6   2]\n",
      " [ 22 202   2   0   0]\n",
      " [ 10   3 544   7   0]\n",
      " [  4   0   6  60   0]\n",
      " [  4   0   2   1 636]]\n"
     ]
    }
   ],
   "source": [
    "# Get the predictions and convert the multicolumn array into class predictions.\n",
    "print(cnn.evaluate(X_test, y_test_target))\n",
    "y_pred2 = np.argmax(cnn.predict(X_test), axis=1)\n",
    "\n",
    "\n",
    "# Plot the confusion matrix and print the final accuracy.\n",
    "print(accuracy_score(y_pred2, y_test))\n",
    "print(confusion_matrix(y_pred2, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer the following questions: (20 points, 5 each)\n",
    "\n",
    "### 1) If we haven't undersampled class 0, we would get a even higher accuracy. (You can check yourself.) Why would this be misleading?\n",
    "\n",
    "### 2) In the previous projects, you used 70-30 and 80-20 train-test splits. Why is a 90-10 split enough for this project?\n",
    "\n",
    "### 3) Why did we need to add a dimension to the dataset before we fed it into a CNN?\n",
    "\n",
    "### 4) Why does a CNN perform better than a feed-forward neural network for the data in this project?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) If we dont do undersampling for the class 0 dataset, the Neural Network models will be more biased towards the class 0 dataset and that could lead to overfitting and not give accurate results for the dataset with other classes which have less number of samples.\n",
      "2) This project involves neural networks which require a lot of data and it will take a lot of time to train the model. Since the point of test set is to test the performance of a given set of parameters at each time we run the model, testing the model on a small dataset is sufficient\n",
      "3)There is a dot product operation between kernel and the input data in convolution operation. For this convolution operation to take place, the input data needs to be represented in 2D dimensional form so that the kernel can slide over the input data and perform the dot product.\n",
      "4) In this project the neural network model has to predict different classes based on the time series data. This means that the neural network needs to learn the features and learn the temporal data and the CNN model can use the kernels and the convolution operation to do this.\n"
     ]
    }
   ],
   "source": [
    "print('1) If we dont do undersampling for the class 0 dataset, the Neural Network models will be more biased towards the class 0 dataset and that could lead to overfitting and not give accurate results for the dataset with other classes which have less number of samples.')\n",
    "print('2) This project involves neural networks which require a lot of data and it will take a lot of time to train the model. Since the point of test set is to test the performance of a given set of parameters at each time we run the model, testing the model on a small dataset is sufficient')\n",
    "print('3)There is a dot product operation between kernel and the input data in convolution operation. For this convolution operation to take place, the input data needs to be represented in 2D dimensional form so that the kernel can slide over the input data and perform the dot product.')\n",
    "print('4) In this project the neural network model has to predict different classes based on the time series data. This means that the neural network needs to learn the features and learn the temporal data and the CNN model can use the kernels and the convolution operation to do this.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
